grafana_agent:
  state: present
  # see: https://github.com/grafana/agent/releases
  version: '0.22.0'
  github:
    user: grafana
    repo: agent
  # default config path: /etc/agent/agent.yaml
  config_file: /etc/grafana-agent.yaml
  user: grafana-agent
  group: grafana-agent
  # default home (installation from .deb) is "/var/lib/grafana-agent"
  home: '/opt/grafana-agent'
  # install method can be either 'deb' or 'archive'
  install_method: 'deb'
  components:
    - agent # size: ~105 MB
    - agentctl # size: ~107MB
  config:
  # see:https://grafana.com/docs/agent/latest/configuration/
  # "config" can also be a URL string
  #
  # example:
  # config: 'http://127.0.0.1/config/grafana-agent.yaml'
  #
  # start grafana-agent with flags:
  # -enable-features=remote-configs
  # -config.url.basic-auth-user <user>
  # -config.url.basic-auth-password-file <file>
    server:
    # see: https://grafana.com/docs/agent/latest/configuration/server-config/
      log_level: info
      http_listen_address: 0.0.0.0
      http_listen_port: 9400
      grpc_listen_address: 127.0.0.1
      grpc_listen_port: 9095
    metrics:
    # see: https://grafana.com/docs/agent/latest/configuration/metrics-config/
      # "wal_directory"
      # The Grafana Agent assumes that all folders within wal_directory are managed by
      # the agent itself.
      #
      # This means if you are using a PVC or docker volume mount, you must point
      # wal_directory to a subdirectory of the mount point
      wal_directory: /var/run/grafana-agent/metrics/wal
      global:
        scrape_interval: ${GRAFANA_AGENT_PROMETHEUS_GLOBAL_SCRAPE_INTERVAL}
        scrape_timeout: ${GRAFANA_AGENT_PROMETHEUS_GLOBAL_SCRAPE_TIMEOUT}
        remote_write:
          - url: ${GRAFANA_AGENT_PROMETHEUS_REMOTE_WRITE_URL}
            basic_auth:
              username: ${GRAFANA_AGENT_PROMETHEUS_REMOTE_WRITE_USERNAME}
              password: ${GRAFANA_AGENT_PROMETHEUS_REMOTE_WRITE_PASSWORD}
      configs:
        # this is essentially the same config as for prometheus
        # see also: defaults/prometheus/main.yml
        - name: prometheus
          scrape_configs:
          # see: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
            - job_name: grafana-agent
              # scrapes the agent's own metrics, see "config.server.http_listen_port" above
              scrape_interval: 1m
              scrape_timeout: 10s
              metrics_path: '/metrics'
              scheme: http
              static_configs:
              # see: https://grafana.com/docs/loki/latest/clients/promtail/configuration/#static_configs
                - targets: ['127.0.0.1:9400']
            - job_name: php-fpm_exporter
              static_configs:
                - targets: ['127.0.0.1:9253']
            - job_name: mysqld_exporter
              static_configs:
                - targets: ['127.0.0.1:9306']
            - job_name: redis_exporter
              static_configs:
                - targets: ['127.0.0.1:9121']
            - job_name: nginx-prometheus-exporter
              static_configs:
                - targets: ['127.0.0.1:9113']
            - job_name: blackbox_exporter
              static_configs:
                - targets: ['127.0.0.1:9115']
    logs:
    # see: https://grafana.com/docs/agent/latest/configuration/logs-config/
      # "positions_diretory"
      # This directory will be automatically created if it doesn't exist.
      # positions file pattern: <positions_directory>/<logs_instance_config.name>.yml
      positions_directory: '/var/run/grafana-agent/logs/positions'
      configs:
      # see: https://grafana.com/docs/agent/latest/configuration/logs-config/#logs_instance_config
        - name: default
          positions:
            filename: /var/run/grafana-agent/logs/positions/default.positions.yaml
          scrape_configs:
          # promtail scrape conf
          # see: https://grafana.com/docs/loki/latest/clients/promtail/scraping/
          # see: https://grafana.com/docs/loki/latest/clients/promtail/configuration/#scrape_configs
            - job_name: varlogs
              static_configs:
                - targets: [localhost]
                  labels:
                    job: varlogs
                    __path__: /var/log/*log
          clients:
            - url: ${GRAFANA_AGENT_PROMTAIL_CLIENT_URL}
              basic_auth:
                username: ${GRAFANA_AGENT_PROMTAIL_CLIENT_USERNAME}
                password: ${GRAFANA_AGENT_PROMTAIL_CLIENT_PASSWORD}
    traces:
    # grafana/tempo integration
      configs:
        - name: default
          remote_write:
            # the remote write endpoint can either be Grafana Cloud or a (local) tempo instance
            # the Agent only exports in OTLP gRPC and HTTP format
            # OTLP default ports are 4317 for gRPC and 4318 for HTTP
            - endpoint:  ${GRAFANA_AGENT_TEMPO_REMOTE_WRITE_ENDPOINT}
              basic_auth:
                username: ${GRAFANA_AGENT_TEMPO_REMOTE_WRITE_USERNAME}
                password: ${GRAFANA_AGENT_TEMPO_REMOTE_WRITE_PASSWORD}
          receivers:
          # > for a production deployment (or to save resources) you should only enable the receivers you need!
          # only jaeger is enabled because it is supported by:
          # * auxmoney/opentracing-bundle - https://github.com/auxmoney/OpentracingBundle-core#choose-tracer-implementation
          # * nginx opentracing plugin - https://github.com/opentracing-contrib/nginx-opentracing#dependencies
          # * spring (boot) opentracing - https://github.com/opentracing-contrib/java-spring-jaeger
            jaeger:
              protocols:
                # most Jaeger Clients use Thrift’s compact encoding
                # see: https://www.jaegertracing.io/docs/1.31/apis/#thrift-over-udp-stable
                # 6831/UDP - jaeger-agent - jaeger.thrift over compact thrift protocol
                thrift_compact:
                # some client libraries do not support it (notably, Node.js) and use Thrift’s binary encoding
                # (because thriftrw npm package does not support compact protocol)
                # see: https://www.jaegertracing.io/docs/1.31/apis/#thrift-over-udp-stable
                # 6832/UDP - jaeger-agent - jaeger.thrift over binary thrift protocol
                thrift_binary:
                # Since Jaeger version 1.11 the official and recommended protocol between Agents and Collectors is gRPC with Protobuf
                # see: https://www.jaegertracing.io/docs/1.31/apis/#protobuf-via-grpc-stable
                # see: https://www.jaegertracing.io/docs/1.31/deployment/#collector
                # 14250/gRPC - jaeger-collector - can be used by jaeger-agent to send spans in model.proto format
                # grpc:
                # https://www.jaegertracing.io/docs/1.31/apis/#thrift-over-http-stable
                # usually not used but useful with i.e. AWS lambda function where the agent is not on the same host
                #thrift_http:
            # zipkin:
            # otlp:
            # # see: https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/otlpreceiver/README.md
            #   protocols:
            #     http:
            #       endpoint: 0.0.0.0:4318
            #       tls:
            #         insecure: true
            #         ca_file: server.crt
            #         cert_file: client.crt
            #         key_file: client.key
            #         min_version: "1.1"
            #         max_version: "1.2"
            #       cors:
            #         allowed_origins:
            #           - '*'
            #           - '*.example.com'
            #         allowed_headers:
            #           - Example-Header
            #         max_age: 7200
            #     grpc:
            #       endpoint: 0.0.0.0:4317
            # opencensus:
          # attributes:
          #   actions:
          #     - action: upsert
          #       key: env
          #       value: prod
          # batch:
          #   timeout: 5s
          #   send_batch_size: 100

          # This processor writes a well formatted log line to a logs instance for each span, root, or process
          # that passes through the Agent. This allows for automatically building a mechanism for trace
          # discovery and building metrics from traces using Loki. It should be considered experimental.
          automatic_logging:
            # backend is either "stdout" or "logs_instance"
            backend: stdout
            # "logs_instance_name" is required if backend is "logs_instance"
            # this is a logs instance inside this config (configured above - see: logs.configs[].name)
            #logs_instance_name: default
            spans: true
            processes: true
            roots: true
          spanmetrics:
          # This is an experimental feature of Opentelemetry-Collector and the behavior
          # may change in the future.
            # handler_endpoint is a prometheus metrics endpoint
            handler_endpoint: 0.0.0.0:8889
            # metrics_instance is a Grafana agent prometheus instance
            # see above: metrics.configs[].name
            #metrics_instance: prometheus
          # service_graphs:
          #   enabled: true
    integrations:
    # see: https://grafana.com/docs/agent/latest/configuration/integrations/
      agent:
        enabled: false
      node_exporter:
      # see: https://grafana.com/docs/agent/latest/configuration/integrations/node-exporter-config/
        enabled: false
        rootfs_path: /
        sysfs_path: /sys
        procfs_path: /proc
      mysqld_exporter:
      # see: https://grafana.com/docs/agent/latest/configuration/integrations/mysqld-exporter-config/
        enabled: false
        # set MYSQL_ALLOW_EMPTY_PASSWORD if password is empty
        data_source_name: "root:root@(127.0.0.1:3306)/"
      redis_exporter:
      # see: https://grafana.com/docs/agent/latest/configuration/integrations/redis-exporter-config/
        enabled: false
        redis_addr: "127.0.0.1:6379"
        relabel_configs:
        - source_labels: [__address__]
          target_label: instance
          replacement: redis
      process_exporter:
      # see: https://grafana.com/docs/agent/latest/configuration/integrations/process-exporter-config/
        enabled: false
        process_names:
        - name: "{{.Comm}}"
          cmdline:
          - '.+'
